{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spam-filter\n",
    "\n",
    "This notebook is used to develop a full NLP pipeline (tokenization, lemmatization, vectorization, cross-validation/testing) for creating a spam filter. The model will be trained/tested using a dataset available on Kaggle: https://www.kaggle.com/uciml/sms-spam-collection-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                      v2  \\\n",
       "0                                        Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...   \n",
       "1                                                                                                                          Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...   \n",
       "3                                                                                                      U dun say so early hor... U c already then say...   \n",
       "4                                                                                          Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "pd.set_option('display.max_colwidth', 150) # Display 150 characters per text message\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text messages that span over multiple columns\n",
    "\n",
    "Some texts 'spill' over onto multiple columns, so I decided to combine these into a new column. Also added column headings for the text message itself and the spam/ham label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
    "\n",
    "df.fillna('', inplace=True)\n",
    "df['text'] = df[cols].apply(lambda x: ' '.join(x.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                    text  \n",
       "0                                     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...     \n",
       "1                                                                                                                       Ok lar... Joking wif u oni...     \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...  \n",
       "3                                                                                                   U dun say so early hor... U c already then say...     \n",
       "4                                                                                       Nah I don't think he goes to usf, he lives around here though     "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Exploring the dataset to see how many rows it has, number of spam/ham messages, average length of texts, etc. This will give me some insight regarding the full dataset before moving onto tokenization and data cleaning (e.g. removing stopwords/lemmatization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label    5572 non-null object\n",
      "text     5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 5572 rows and 2 columns\n",
      "There are 747 messages labelled as spam, and 4825 messages labelled as ham\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Dataset has {} rows and {} columns'.format(len(df), len(df.columns)))\n",
    "print('There are {} messages labelled as spam, and {} messages labelled as ham'.format(len(df[df['label']=='spam']),\n",
    "                                                                                       len(df[df['label']=='ham'])))\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"label\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average message length = 83.68\n",
      "Average number of punctuation marks in message = 4.27\n"
     ]
    }
   ],
   "source": [
    "print('Average message length = {}'.format(round(df['text'].apply(lambda x: len(x)).mean(), 2)))\n",
    "print('Average number of punctuation marks in message = {}'.format(round(df['text'].apply(lambda x: sum([1 for char in x if char in string.punctuation])).mean(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "After some preliminary exploratory data analysis, the next step is data cleaning. This involves:\n",
    "1. **removing punctuation** - for this exercise I'm assuming that the number of punctuation marks in each message does not directly contribute to whether the message is spam/ham; realistically, this should be taken into account\n",
    "2. **tokenization** - splitting the message up into a list of individual words\n",
    "3. **removing stop words** - common words such as 'the', 'from', 'in', etc. are assumed to be filler words and do not contribute to the meaning/semantics of the message\n",
    "4. **lemmatization** - grouping together inflected forms of a word so they can be analysed as a single term; I chose this method over stemming as it is generally more accurate, as stemming simply 'cuts down' words in a crude manner\n",
    "\n",
    "Generally some of these processes are available through packages such as NLTK, but I will try to write most of the code myself to improve my understanding of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0                                     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...      \n",
       "1                                                                                                                       Ok lar... Joking wif u oni...      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...   \n",
       "3                                                                                                   U dun say so early hor... U c already then say...      \n",
       "4                                                                                       Nah I don't think he goes to usf, he lives around here though      \n",
       "\n",
       "                                                                                                                                            text_nopunct  \n",
       "0                                              Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat     \n",
       "1                                                                                                                             Ok lar Joking wif u oni     \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...  \n",
       "3                                                                                                         U dun say so early hor U c already then say     \n",
       "4                                                                                         Nah I dont think he goes to usf he lives around here though     "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    new_text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return new_text\n",
    "\n",
    "df['text_nopunct'] = df['text'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0                                     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...      \n",
       "1                                                                                                                       Ok lar... Joking wif u oni...      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...   \n",
       "3                                                                                                   U dun say so early hor... U c already then say...      \n",
       "4                                                                                       Nah I don't think he goes to usf, he lives around here though      \n",
       "\n",
       "                                                                                                                                            text_nopunct  \\\n",
       "0                                              Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat      \n",
       "1                                                                                                                             Ok lar Joking wif u oni      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...   \n",
       "3                                                                                                         U dun say so early hor U c already then say      \n",
       "4                                                                                         Nah I dont think he goes to usf he lives around here though      \n",
       "\n",
       "                                                                                                                                          text_tokenized  \n",
       "0                            [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]  \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...  \n",
       "3                                                                                                [u, dun, say, so, early, hor, u, c, already, then, say]  \n",
       "4                                                                              [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokenized_list = re.split('\\W+', text) # Use regular expressions to split string along non-alphanumeric characters\n",
    "    return tokenized_list[:-1]\n",
    "\n",
    "# Make all characters lower case since Python is case sensitive, reduces total number of terms\n",
    "df['text_tokenized'] = df['text_nopunct'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common stopwords in the English language that don't add semantic value to a message\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0                                     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...      \n",
       "1                                                                                                                       Ok lar... Joking wif u oni...      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...   \n",
       "3                                                                                                   U dun say so early hor... U c already then say...      \n",
       "4                                                                                       Nah I don't think he goes to usf, he lives around here though      \n",
       "\n",
       "                                                                                                                                            text_nopunct  \\\n",
       "0                                              Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat      \n",
       "1                                                                                                                             Ok lar Joking wif u oni      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...   \n",
       "3                                                                                                         U dun say so early hor U c already then say      \n",
       "4                                                                                         Nah I dont think he goes to usf he lives around here though      \n",
       "\n",
       "                                                                                                                                          text_tokenized  \\\n",
       "0                            [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]   \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...   \n",
       "3                                                                                                [u, dun, say, so, early, hor, u, c, already, then, say]   \n",
       "4                                                                              [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "\n",
       "                                                                                                                                             text_nostop  \n",
       "0                                                    [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...  \n",
       "3                                                                                                          [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                                                                   [nah, dont, think, goes, usf, lives, around, though]  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text_list):\n",
    "    new_list = [word for word in text_list if word not in stopwords]\n",
    "    return new_list\n",
    "\n",
    "df['text_nostop'] = df['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_nostop</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 0845281007...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, then, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0                                     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...      \n",
       "1                                                                                                                       Ok lar... Joking wif u oni...      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 0845281007...   \n",
       "3                                                                                                   U dun say so early hor... U c already then say...      \n",
       "4                                                                                       Nah I don't think he goes to usf, he lives around here though      \n",
       "\n",
       "                                                                                                                                            text_nopunct  \\\n",
       "0                                              Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat      \n",
       "1                                                                                                                             Ok lar Joking wif u oni      \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over...   \n",
       "3                                                                                                         U dun say so early hor U c already then say      \n",
       "4                                                                                         Nah I dont think he goes to usf he lives around here though      \n",
       "\n",
       "                                                                                                                                          text_tokenized  \\\n",
       "0                            [go, until, jurong, point, crazy, available, only, in, bugis, n, great, world, la, e, buffet, cine, there, got, amore, wat]   \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to, 87121, to, receive, entry, questionstd, txt, rat...   \n",
       "3                                                                                                [u, dun, say, so, early, hor, u, c, already, then, say]   \n",
       "4                                                                              [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "\n",
       "                                                                                                                                             text_nostop  \\\n",
       "0                                                    [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]   \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...   \n",
       "3                                                                                                          [u, dun, say, early, hor, u, c, already, say]   \n",
       "4                                                                                                   [nah, dont, think, goes, usf, lives, around, though]   \n",
       "\n",
       "                                                                                                                                         text_lemmatized  \n",
       "0                                                    [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]  \n",
       "1                                                                                                                         [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 084528...  \n",
       "3                                                                                                          [u, dun, say, early, hor, u, c, already, say]  \n",
       "4                                                                                                      [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer() # Using WordNet lemmatizer avaialable from the NLTK package\n",
    "\n",
    "def lemmatize_text(text_list):\n",
    "    new_list = [wnl.lemmatize(word) for word in text_list]\n",
    "    return new_list\n",
    "\n",
    "df['text_lemmatized'] = df['text_nostop'].apply(lambda x: lemmatize_text(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
